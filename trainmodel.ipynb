{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b81667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy rdkit-pypi scikit-learn joblib\n",
    "!pip install tensorflow -U -q  # On Kaggle\n",
    "#Operating on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n",
    "\n",
    "target_columns = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']  \n",
    "smiles_column = 'SMILES'  \n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "print(\"数据集基本信息：\")\n",
    "print(f\"总样本数：{len(train_data)}\")\n",
    "print(\"各指标非空样本数：\")\n",
    "print(train_data[target_columns].notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92621461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fingerprint(smiles, radius=2, n_bits=2048):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None: \n",
    "            return None\n",
    "\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(\n",
    "            mol, radius=radius, nBits=n_bits\n",
    "        )\n",
    "\n",
    "        return np.array(fingerprint)\n",
    "    except Exception as e:\n",
    "        print(f\"处理SMILES时出错: {smiles}, 错误: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"开始生成分子指纹...\")\n",
    "train_data['fingerprint'] = train_data[smiles_column].apply(smiles_to_fingerprint)\n",
    "\n",
    "valid_mask = train_data['fingerprint'].notnull()\n",
    "train_data = train_data[valid_mask].copy()\n",
    "print(f\"有效样本数: {len(train_data)} (已过滤无效SMILES或指纹生成失败的样本)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'FFV'\n",
    "\n",
    "target_data = train_data.dropna(subset=[target]).copy()\n",
    "X = np.stack(target_data['fingerprint'].values)\n",
    "y = target_data[target].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0005)),\n",
    "    \n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_absolute_error'  \n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_train_pred = model.predict(X_train).flatten()\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "print(f\"训练集MAE: {mean_absolute_error(y_train, y_train_pred):.4f}\")\n",
    "print(f\"验证集MAE: {mean_absolute_error(y_val, y_val_pred):.4f}\")\n",
    "\n",
    "model.save(f\"models/mlp_{target}_model.h5\")\n",
    "\n",
    "joblib.dump(scaler, f\"models/scaler_{target}_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6116aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'criterion': 'absolute_error',\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in target_columns:\n",
    "    if target != 'FFV':\n",
    "        results = {}  \n",
    "        \n",
    "        print(f\"\\n----- 开始训练 {target} 模型 -----\")\n",
    "  \n",
    "        target_data = train_data.dropna(subset=[target]).copy()\n",
    "        print(f\"用于训练{target}的样本数: {len(target_data)}\")\n",
    "\n",
    "        X = np.stack(target_data['fingerprint'].values)\n",
    "        y = target_data[target].values\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        model = RandomForestRegressor(** rf_params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        \n",
    "        results[target] = {\n",
    "            'train_samples': len(X_train),\n",
    "            'val_samples': len(X_val),\n",
    "            'train_mae': train_mae,\n",
    "            'val_mae': val_mae\n",
    "        }\n",
    "        \n",
    "        print(f\"{target} 模型训练集MAE: {train_mae:.4f}\")\n",
    "        print(f\"{target} 模型验证集MAE: {val_mae:.4f}\")\n",
    "\n",
    "        model_path = f\"models/rf_{target}_model.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"{target} 模型已保存至: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52faf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "\n",
    "test_data = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')\n",
    "\n",
    "def generate_fingerprint(smiles, radius=2, nBits=2048):\n",
    "    \"\"\"从SMILES生成分子指纹\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return np.zeros(nBits)\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return np.zeros(nBits)\n",
    "\n",
    "if 'SMILES' in test_data.columns:\n",
    "    print(\"从SMILES生成指纹特征...\")\n",
    "    test_data['fingerprint'] = test_data['SMILES'].apply(generate_fingerprint)\n",
    "else:\n",
    "    raise ValueError(\"测试数据中既没有'fingerprint'列也没有'SMILES'列，无法生成特征\")\n",
    "\n",
    "X_test = np.stack(test_data['fingerprint'].values)\n",
    "\n",
    "scaler = joblib.load('models/scaler_FFV_model.pkl')\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for target in target_columns:\n",
    "    print(f\"预测 {target}...\")\n",
    "    \n",
    "    if target == 'FFV':\n",
    "        model = load_model(f\"models/mlp_{target}_model.h5\")\n",
    "        predictions = model.predict(X_test_scaled).flatten()\n",
    "    else:\n",
    "        model = joblib.load(f\"models/rf_{target}_model.pkl\")\n",
    "        predictions = model.predict(X_test)\n",
    "    \n",
    "    submission[target] = predictions\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"提交文件已生成: submission.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
